{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.svar_model import SVAR\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_excel('DATA.xlsx')\n",
    "#data['Date'] = pd.PeriodIndex(data['Date'], freq='Q')\n",
    "#data.set_index('Date', inplace=True)\n",
    "\n",
    "# Select the sample period (1948Q1 to 1994Q4)\n",
    "#data = data.loc['1948Q1':'1994Q4']\n",
    "\n",
    "# Step 2: Define variables based on nchoice\n",
    "nchoice = 2  # 1 for employment, 2 for hours\n",
    "if nchoice == 1:\n",
    "    nx = data['LHEM']\n",
    "    labor = 'employment'\n",
    "elif nchoice == 2:\n",
    "    nx = data['LPMHU']\n",
    "    labor = 'hours'\n",
    "\n",
    "# Step 3: Compute variables\n",
    "yx = data['GDPQ']\n",
    "xx = yx / nx\n",
    "\n",
    "# Create index numbers starting at 100\n",
    "y = 100 + 100 * np.log(yx / yx.iloc[0])\n",
    "n = 100 + 100 * np.log(nx / nx.iloc[0])\n",
    "x = 100 + 100 * np.log(xx / xx.iloc[0])\n",
    "\n",
    "# Compute first differences\n",
    "dy = y.diff()\n",
    "dn = n.diff()\n",
    "dx = x.diff()\n",
    "\n",
    "# Step 4: Handle the transformation of 'n' based on nint and difn\n",
    "nint = 1  # 1 if 'n' is I(1), 0 if 'n' is I(0)\n",
    "difn = 'yes'  # 'yes' to use first differences, 'no' to use detrended series\n",
    "\n",
    "if nint == 0:\n",
    "    # Detrend 'n' by regressing on a constant and trend\n",
    "    trend = np.arange(len(n))\n",
    "    n_trend = pd.DataFrame({'n': n, 'trend': trend})\n",
    "    n_detrended = n_trend['n'] - np.polyval(np.polyfit(trend, n_trend['n'], 1), trend)\n",
    "    dnz = n_detrended\n",
    "else:\n",
    "    # Use first differences\n",
    "    dnz = dn\n",
    "\n",
    "# If difn is 'no' and nint is 0, use the detrended 'n' for 'dn'\n",
    "if nint == 0 and difn == 'no':\n",
    "    dn = n_detrended\n",
    "\n",
    "# Step 5: Prepare data for VAR\n",
    "var_data = pd.DataFrame({'dx': dx, 'dnz': dnz}).dropna()\n",
    "\n",
    "# Step 6: Estimate the reduced-form VAR\n",
    "model = VAR(var_data)\n",
    "results = model.fit(4)  # Using 4 lags as in the RATS code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Fit the SVAR model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m svar_model \u001b[38;5;241m=\u001b[39m SVAR(var_data, svar_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, A\u001b[38;5;241m=\u001b[39mA)\n\u001b[1;32m----> 7\u001b[0m svar_results \u001b[38;5;241m=\u001b[39m \u001b[43msvar_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Proceed with structural shocks and impulse responses\u001b[39;00m\n\u001b[0;32m     10\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m svar_results\u001b[38;5;241m.\u001b[39mresid\n",
      "File \u001b[1;32mc:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\svar_model.py:181\u001b[0m, in \u001b[0;36mSVAR.fit\u001b[1;34m(self, A_guess, B_guess, maxlags, method, ic, trend, verbose, s_method, solver, override, maxiter, maxfun)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# initialize starting parameters\u001b[39;00m\n\u001b[0;32m    179\u001b[0m start_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_init_params(A_guess, B_guess)\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_svar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m                           \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxfun\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\svar_model.py:249\u001b[0m, in \u001b[0;36mSVAR._estimate_svar\u001b[1;34m(self, start_params, lags, maxiter, maxfun, trend, solver, override)\u001b[0m\n\u001b[0;32m    246\u001b[0m omega \u001b[38;5;241m=\u001b[39m sse \u001b[38;5;241m/\u001b[39m df_resid\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_u \u001b[38;5;241m=\u001b[39m omega\n\u001b[1;32m--> 249\u001b[0m A, B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_solve_AB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m                      \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m A_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA_mask\n\u001b[0;32m    253\u001b[0m B_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB_mask\n",
      "File \u001b[1;32mc:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\svar_model.py:355\u001b[0m, in \u001b[0;36mSVAR._solve_AB\u001b[1;34m(self, start_params, maxiter, override, solver)\u001b[0m\n\u001b[0;32m    353\u001b[0m     J \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_J(A, B)\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_order(J)\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m#TODO: change to a warning?\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrder/rank conditions have not been checked\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\svar_model.py:434\u001b[0m, in \u001b[0;36mSVAR.check_rank\u001b[1;34m(self, J)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_rank\u001b[39m(\u001b[38;5;28mself\u001b[39m, J):\n\u001b[1;32m--> 434\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39msize(J, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRank condition not met: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution may not be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:1924\u001b[0m, in \u001b[0;36mmatrix_rank\u001b[1;34m(A, tol, hermitian)\u001b[0m\n\u001b[0;32m   1922\u001b[0m S \u001b[38;5;241m=\u001b[39m svd(A, compute_uv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, hermitian\u001b[38;5;241m=\u001b[39mhermitian)\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1924\u001b[0m     tol \u001b[38;5;241m=\u001b[39m \u001b[43mS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]) \u001b[38;5;241m*\u001b[39m finfo(S\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39meps\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1926\u001b[0m     tol \u001b[38;5;241m=\u001b[39m asarray(tol)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, newaxis]\n",
      "File \u001b[1;32mc:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the identification matrix for the SVAR model\n",
    "A = np.array([[np.nan, 0], \n",
    "              [np.nan, np.nan]])\n",
    "\n",
    "# Fit the SVAR model\n",
    "svar_model = SVAR(var_data, svar_type='A', A=A)\n",
    "svar_results = svar_model.fit()\n",
    "\n",
    "# Proceed with structural shocks and impulse responses\n",
    "epsilon = svar_results.resid\n",
    "irf = svar_results.irf(10)\n",
    "\n",
    "# Step 8: Obtain structural shocks and impulse responses\n",
    "epsilon = svar_results.resid\n",
    "nsteps = 13  # Number of periods for impulse responses\n",
    "irf = svar_results.irf(nsteps)\n",
    "\n",
    "# Step 9: Compute contributions of each shock (Historical Decomposition)\n",
    "# Note: statsmodels does not have built-in historical decomposition, so we approximate it\n",
    "# by filtering the shocks through the impulse responses\n",
    "\n",
    "# Initialize arrays to store contributions\n",
    "dx_tech = np.zeros(len(var_data))\n",
    "dx_nontech = np.zeros(len(var_data))\n",
    "dn_tech = np.zeros(len(var_data))\n",
    "dn_nontech = np.zeros(len(var_data))\n",
    "\n",
    "# Get structural impulse responses\n",
    "irf_values = irf.irfs  # Shape: (nsteps+1, nvars, nvars)\n",
    "\n",
    "# Loop over time to compute contributions\n",
    "for t in range(4, len(var_data)):  # Start from index equal to the number of lags\n",
    "    contrib_tech = np.zeros(2)\n",
    "    contrib_nontech = np.zeros(2)\n",
    "    for i in range(nsteps):\n",
    "        if t - i >= 0:\n",
    "            shock = epsilon.iloc[t - i]\n",
    "            contrib_tech += irf_values[i, :, 0] * shock[0]\n",
    "            contrib_nontech += irf_values[i, :, 1] * shock[1]\n",
    "    dx_tech[t] = contrib_tech[0]\n",
    "    dn_tech[t] = contrib_tech[1]\n",
    "    dx_nontech[t] = contrib_nontech[0]\n",
    "    dn_nontech[t] = contrib_nontech[1]\n",
    "\n",
    "# Step 10: Compute conditional correlations\n",
    "# Technology component\n",
    "corr_tech = np.corrcoef(dn_tech[4:], dx_tech[4:])[0, 1]\n",
    "# Non-technology component\n",
    "corr_nontech = np.corrcoef(dn_nontech[4:], dx_nontech[4:])[0, 1]\n",
    "\n",
    "print(\"Conditional Correlation (Technology Shock):\", corr_tech)\n",
    "print(\"Conditional Correlation (Non-Technology Shock):\", corr_nontech)\n",
    "\n",
    "# Step 11: Generate Figure 1 - Scatter plots\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Original data\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(dn[4:], dx[4:], alpha=0.5)\n",
    "plt.title('Data')\n",
    "plt.xlabel('dn')\n",
    "plt.ylabel('dx')\n",
    "\n",
    "# Technology component\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(dn_tech[4:], dx_tech[4:], alpha=0.5)\n",
    "plt.title('Technology Component')\n",
    "plt.xlabel('dn (tech)')\n",
    "plt.ylabel('dx (tech)')\n",
    "\n",
    "# Non-Technology component\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(dn_nontech[4:], dx_nontech[4:], alpha=0.5)\n",
    "plt.title('Non-Technology Component')\n",
    "plt.xlabel('dn (non-tech)')\n",
    "plt.ylabel('dx (non-tech)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 12: Generate Figure 2 - Impulse Responses\n",
    "irf.plot(orth=False, impulse='dx', response='dx', figsize=(12, 8))\n",
    "plt.suptitle('Impulse Response of dx to Shocks', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "irf.plot(orth=False, impulse='dnz', response='dnz', figsize=(12, 8))\n",
    "plt.suptitle('Impulse Response of dn to Shocks', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Additional plots for other variables can be generated similarly\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
