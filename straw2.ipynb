{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.svar_model import SVAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = pd.read_excel('DATA.xlsx')\n",
    "\n",
    "\n",
    "# Step 2: Define variables based on nchoice\n",
    "nchoice = 2  # 1 for employment, 2 for hours\n",
    "if nchoice == 1:\n",
    "    nx = data['LHEM']\n",
    "    labor = 'employment'\n",
    "elif nchoice == 2:\n",
    "    nx = data['LPMHU']\n",
    "    labor = 'hours'\n",
    "\n",
    "# Step 3: Compute variables\n",
    "yx = data['GDPQ']\n",
    "xx = yx / nx\n",
    "\n",
    "# Create index numbers starting at 100\n",
    "y = 100 + 100 * np.log(yx / yx.iloc[0])\n",
    "n = 100 + 100 * np.log(nx / nx.iloc[0])\n",
    "x = 100 + 100 * np.log(xx / xx.iloc[0])\n",
    "\n",
    "# Compute first differences\n",
    "dy = y.diff()\n",
    "dn = n.diff()\n",
    "dx = x.diff()\n",
    "\n",
    "# Step 4: Handle the transformation of 'n' based on nint and difn\n",
    "nint = 1  # 1 if 'n' is I(1), 0 if 'n' is I(0)\n",
    "difn = 'yes'  # 'yes' to use first differences, 'no' to use detrended series\n",
    "\n",
    "if nint == 0:\n",
    "    # Detrend 'n' by regressing on a constant and trend\n",
    "    trend = np.arange(len(n))\n",
    "    n_trend = pd.DataFrame({'n': n, 'trend': trend})\n",
    "    coeffs = np.polyfit(trend[~n.isna()], n[~n.isna()], 1)\n",
    "    n_trend_line = np.polyval(coeffs, trend)\n",
    "    n_detrended = n - n_trend_line\n",
    "    dnz = n_detrended\n",
    "else:\n",
    "    # Use first differences\n",
    "    dnz = dn\n",
    "\n",
    "# If difn is 'no' and nint is 0, use the detrended 'n' for 'dn'\n",
    "if nint == 0 and difn == 'no':\n",
    "    dn = n_detrended\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VARResults' object has no attribute 'coefs_companion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_ar\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mirf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IRAnalysis\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Compute the long-run effects matrix from the reduced-form VAR\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# First, get the companion form\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m companion_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefs_companion\u001b[49m\n\u001b[0;32m     22\u001b[0m identity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(companion_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Compute the long-run matrix\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\miniconda3\\Lib\\site-packages\\statsmodels\\base\\wrapper.py:34\u001b[0m, in \u001b[0;36mResultsWrapper.__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m     36\u001b[0m how \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_attrs\u001b[38;5;241m.\u001b[39mget(attr)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VARResults' object has no attribute 'coefs_companion'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure that all series are aligned and drop missing values\n",
    "data_var = pd.DataFrame({'dx': dx, 'dnz': dnz}).dropna()\n",
    "\n",
    "# Step 5: Estimate the reduced-form VAR\n",
    "model = VAR(data_var)\n",
    "results = model.fit(4)  # Using 4 lags as in the RATS code\n",
    "\n",
    "# Step 6: Identify the structural VAR using long-run restrictions\n",
    "# The long-run impact of the second shock on 'dx' is restricted to zero\n",
    "# That is, only technology shocks have permanent effects on productivity\n",
    "\n",
    "# The long-run restriction matrix (A) should have the form:\n",
    "# [[a11, 0],\n",
    "#  [a21, a22]]\n",
    "# We set the (1,2) element to zero to impose the long-run restriction\n",
    "\n",
    "from statsmodels.tsa.vector_ar.irf import IRAnalysis\n",
    "\n",
    "# Compute the long-run effects matrix from the reduced-form VAR\n",
    "# First, get the companion form\n",
    "companion_matrix = results.coefs_companion\n",
    "identity = np.eye(companion_matrix.shape[0])\n",
    "\n",
    "# Compute the long-run matrix\n",
    "long_run_matrix = np.linalg.inv(identity - companion_matrix)[:2, :2]\n",
    "\n",
    "# Impose the long-run restriction that the second shock does not affect 'dx' in the long run\n",
    "# This restriction implies that the (1,2) element of the cumulative impulse response is zero\n",
    "\n",
    "# Now, we set up the matrices needed for identification\n",
    "B = np.array([[np.nan, 0],\n",
    "              [np.nan, np.nan]])\n",
    "\n",
    "# We can estimate the SVAR with the long-run restriction using statsmodels\n",
    "svar_model = SVAR(data_var, svar_type='longrun', A=B)\n",
    "svar_results = svar_model.fit(4)\n",
    "\n",
    "# Step 7: Obtain the structural MA representation (Impulse Responses)\n",
    "nsteps = 40  # Number of periods for impulse responses\n",
    "irf = svar_results.irf(nsteps)\n",
    "\n",
    "# Get the impulse response functions\n",
    "irfs = irf.irfs  # Shape: (nsteps+1, nvars, nvars)\n",
    "\n",
    "# Step 8: Compute the MA coefficients (Cumulative Impulse Responses)\n",
    "# Since we need the cumulative sum for levels\n",
    "cum_irfs = np.cumsum(irfs, axis=0)\n",
    "\n",
    "# Step 9: Compute conditional variances and covariances using MA coefficients\n",
    "# For productivity ('dx') and hours ('dnz')\n",
    "\n",
    "# Extract MA coefficients for 'dx' and 'dnz' responses to each shock\n",
    "# Let's denote:\n",
    "# - C_11: response of 'dx' to technology shock\n",
    "# - C_12: response of 'dx' to non-technology shock\n",
    "# - C_21: response of 'dnz' to technology shock\n",
    "# - C_22: response of 'dnz' to non-technology shock\n",
    "\n",
    "C_11 = irfs[:, 0, 0]  # 'dx' response to tech shock\n",
    "C_12 = irfs[:, 0, 1]  # 'dx' response to non-tech shock\n",
    "C_21 = irfs[:, 1, 0]  # 'dnz' response to tech shock\n",
    "C_22 = irfs[:, 1, 1]  # 'dnz' response to non-tech shock\n",
    "\n",
    "# Compute variances of 'dx' and 'dnz' for each component\n",
    "# Variance due to technology shock\n",
    "var_dx_tech = np.sum(C_11 ** 2)\n",
    "var_dnz_tech = np.sum(C_21 ** 2)\n",
    "cov_dx_dnz_tech = np.sum(C_11 * C_21)\n",
    "\n",
    "# Variance due to non-technology shock\n",
    "var_dx_nontech = np.sum(C_12 ** 2)\n",
    "var_dnz_nontech = np.sum(C_22 ** 2)\n",
    "cov_dx_dnz_nontech = np.sum(C_12 * C_22)\n",
    "\n",
    "# Compute conditional correlations\n",
    "corr_tech = cov_dx_dnz_tech / np.sqrt(var_dx_tech * var_dnz_tech)\n",
    "corr_nontech = cov_dx_dnz_nontech / np.sqrt(var_dx_nontech * var_dnz_nontech)\n",
    "\n",
    "print(\"Conditional Correlation (Technology Shock):\", corr_tech)\n",
    "print(\"Conditional Correlation (Non-Technology Shock):\", corr_nontech)\n",
    "\n",
    "# Step 10: Generate Figure 1 - Scatter plots of innovations\n",
    "# Obtain structural shocks (innovations)\n",
    "epsilon = svar_results.resid\n",
    "\n",
    "# Note: Since the shocks are already estimated, we can use them directly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scatter plots of the structural shocks\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Technology shock component\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(epsilon.iloc[:, 0], epsilon.iloc[:, 1], alpha=0.5)\n",
    "plt.title('Structural Innovations')\n",
    "plt.xlabel('Technology Shock')\n",
    "plt.ylabel('Non-Technology Shock')\n",
    "\n",
    "# Scatter plot of contributions to 'dx' and 'dnz' due to technology shock\n",
    "# Compute contributions at each point in time using MA coefficients\n",
    "dx_tech = svar_results.fittedvalues['dx']\n",
    "dnz_tech = svar_results.fittedvalues['dnz']\n",
    "\n",
    "# Since we cannot directly get the contributions from statsmodels, we can approximate\n",
    "# For illustration purposes, we can plot the innovations\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(epsilon.iloc[:, 0], epsilon.iloc[:, 1], alpha=0.5)\n",
    "plt.title('Contributions of Shocks to Variables')\n",
    "plt.xlabel('Tech Shock Contribution to dx')\n",
    "plt.ylabel('Tech Shock Contribution to dnz')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 11: Generate Figure 2 - Impulse Responses\n",
    "# Plot the impulse responses using the MA coefficients\n",
    "\n",
    "# Impulse Response of 'dx' to Technology and Non-Technology Shocks\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(irfs[:, 0, 0], label='dx response to Technology Shock')\n",
    "plt.plot(irfs[:, 0, 1], label='dx response to Non-Technology Shock')\n",
    "plt.title('Impulse Responses of dx')\n",
    "plt.xlabel('Periods')\n",
    "plt.ylabel('Response')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Impulse Response of 'dnz' to Technology and Non-Technology Shocks\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(irfs[:, 1, 0], label='dnz response to Technology Shock')\n",
    "plt.plot(irfs[:, 1, 1], label='dnz response to Non-Technology Shock')\n",
    "plt.title('Impulse Responses of dnz')\n",
    "plt.xlabel('Periods')\n",
    "plt.ylabel('Response')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 12: Generate Figure 3 - Cumulative Impulse Responses\n",
    "# Plot cumulative impulse responses to see long-run effects\n",
    "\n",
    "# Cumulative Impulse Response of 'dx'\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cum_irfs[:, 0, 0], label='Cumulative dx response to Technology Shock')\n",
    "plt.plot(cum_irfs[:, 0, 1], label='Cumulative dx response to Non-Technology Shock')\n",
    "plt.title('Cumulative Impulse Responses of dx')\n",
    "plt.xlabel('Periods')\n",
    "plt.ylabel('Cumulative Response')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Cumulative Impulse Response of 'dnz'\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cum_irfs[:, 1, 0], label='Cumulative dnz response to Technology Shock')\n",
    "plt.plot(cum_irfs[:, 1, 1], label='Cumulative dnz response to Non-Technology Shock')\n",
    "plt.title('Cumulative Impulse Responses of dnz')\n",
    "plt.xlabel('Periods')\n",
    "plt.ylabel('Cumulative Response')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_decomposition(svar_results, nsteps):\n",
    "    # Number of observations and variables\n",
    "    nobs = svar_results.nobs\n",
    "    nvars = svar_results.neqs\n",
    "\n",
    "    # Initialize arrays to store contributions\n",
    "    contributions = np.zeros((nobs + nsteps, nvars, nvars))  # [time, variable, shock]\n",
    "\n",
    "    # Get structural shocks\n",
    "    shocks = svar_results.resid.values\n",
    "\n",
    "    # Get impulse responses\n",
    "    irfs = svar_results.irf(nsteps).irfs  # Shape: (nsteps+1, nvars, nvars)\n",
    "\n",
    "    # Loop over time\n",
    "    for t in range(nobs):\n",
    "        for i in range(nsteps + 1):\n",
    "            if t + i < nobs + nsteps:\n",
    "                contributions[t + i, :, :] += np.outer(irfs[i], shocks[t])\n",
    "\n",
    "    return contributions\n",
    "\n",
    "# Use the function to compute contributions\n",
    "contributions = historical_decomposition(svar_results, nsteps=40)\n",
    "\n",
    "# Sum contributions over shocks to get the total\n",
    "total_contributions = contributions.sum(axis=2)\n",
    "\n",
    "# Plot the contributions of technology shock to 'dx'\n",
    "dx_tech_contribution = contributions[:, 0, 0]  # Variable 'dx', shock 'technology'\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data_var.index, dx[4:], label='Observed dx')\n",
    "plt.plot(data_var.index, dx_tech_contribution[4:nobs + 4], label='Technology Shock Contribution to dx')\n",
    "plt.title('Historical Decomposition of dx')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('dx')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
